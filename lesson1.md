# 书生·浦语大模型

### 2代性能特点：
* 20w上下文
* 推理数学代码能力提升
* 结构化创作
* 工具调用能力
* 内生计算、代码解释
* InternLM2 的核心理念在于回归语言建模的本质，通过提高语料质量及信息密度，实现base model在语言建模能力上的质的提升

### 2代与1代相比的优势
1. 性能全方位提升
   对于其他参数量类似的开源模型，基本是全方位的超越，特别是推理、数学、代码等方面的能力提升尤为显著，并且在人文关怀、想象力创作、工具调用能力等方面都实现了提升
   ![image](https://github.com/ZiyingHuang/InternLM/assets/140309330/144243f8-6ca0-4603-bc56-92f52a4adf03)
2. 强大的计算能力
   InternLM2在自身强大的数学计算能力此基础上，配合代码解释器，更上一层楼。除此之外，还有实用的数据分析：可以读表格，分析数据、绘制统计图表、调用机器学习算法等

### 从模型到应用
合理选择模型（模型评测）
1）首先考虑模型的业务场景是否复杂，从而决定是否微调模型
2）若场景不复杂则直接进行5），若场景复杂则需要考虑算力是否足够
3）若算力足够，则对模型继续训练或进行全参数微调，否则对部分参数进行微调
4）考虑是否需要环境交互，如需要，则需构建智能体，如不需要，直接进行5） 
5）进行模型评测 
6）模型评测通过后部署模型
![image](https://github.com/ZiyingHuang/InternLM/assets/140309330/c03b8fa6-382f-48c3-9da8-54ccd413aba1)

### 全链条开放体系
数据->预训练->微调->部署->评测->应用
1. 数据
书生万卷1.0：
包含了文本数据、图像文本数据集、视频数据
具有多模态融合、精细化处理、价值观对齐的特点
opendatalab数据平台
丰富多样的开放数据、飞速成长的数据量、模态和数据规模、较为全面的服务与工具
2. 预训练
具有高可扩展、极致性能优化、兼容主流以及开箱即用的特点
3. 微调
主要方式：增量续训、有监督微调
XTUNER微调框架
具有适配多种生态、适配多种硬件、极致的显存优化的特点
4. 评测
OPENCOMPASS评测体系
5. 部署
模型特点：
内存开销巨大
动态shape
模型结构相对简单
技术挑战：
设备、推理、服务
部署方案： 技术点：模型并行、低比特量比、Attention优化、计算和访存优化、Continuous Batching
LMDeploy平台介绍
6. 智能体
需求：大语言模型有局限性
轻量级智能体框架Lagent介绍
多模态智能体工具箱AgentLego介绍
